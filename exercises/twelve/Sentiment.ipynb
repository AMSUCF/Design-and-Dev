{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\an111789\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\an111789\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This demo is adapted from https://programminghistorian.org/en/lessons/sentiment-analysis\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# the variable 'message_text' now contains the text we will analyze.\n",
    "message_text = '''Like you, I am getting very frustrated with this process. I am genuinely trying to be as reasonable as possible. I am not trying to \"hold up\" the deal at the last minute. I'm afraid that I am being asked to take a fairly large leap of faith after this company (I don't mean the two of you -- I mean Enron) has screwed me and the people who work for me.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like you, I am getting very frustrated with this process. I am genuinely trying to be as reasonable as possible. I am not trying to \"hold up\" the deal at the last minute. I'm afraid that I am being asked to take a fairly large leap of faith after this company (I don't mean the two of you -- I mean Enron) has screwed me and the people who work for me.\n",
      "compound: -0.3804, neg: 0.093, neu: 0.836, pos: 0.071, "
     ]
    }
   ],
   "source": [
    "print(message_text)\n",
    "\n",
    "# Calling the polarity_scores method on sid and passing in the message_text outputs a dictionary with negative, neutral, positive, and compound scores for the input text\n",
    "scores = sid.polarity_scores(message_text)\n",
    "for key in sorted(scores):\n",
    "        print('{0}: {1}, '.format(key, scores[key]), end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Context from the article above:\n",
    "\n",
    "VADER collects and scores negative, neutral, and positive words and features (and accounts for factors like negation along the way). The “neg”, “neu”, and “pos” values describe the fraction of weighted scores that fall into each category. VADER also sums all weighted scores to calculate a “compound” value normalized between -1 and 1; this value attempts to describe the overall affect of the entire text from strongly negative (-1) to strongly positive (1). In this case, the VADER analysis describes the passage as slightly-to-moderately negative (-0.3804). We can think of this value as estimating the overall impression of an average reader when considering the e-mail as a whole, despite some ambiguity and ambivalence along the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems to me we are in the middle of no man's land with respect to the  following:  Opec production speculation, Mid east crisis and renewed  tensions, US elections and what looks like a slowing economy (?\n",
      "compound: -0.5267, neg: 0.197, neu: 0.68, pos: 0.123, \n",
      "), and no real weather anywhere in the world.\n",
      "compound: -0.296, neg: 0.216, neu: 0.784, pos: 0.0, \n",
      "I think it would be most prudent to play  the markets from a very flat price position and try to day trade more aggressively.\n",
      "compound: 0.0183, neg: 0.103, neu: 0.792, pos: 0.105, \n",
      "I have no intentions of outguessing Mr. Greenspan, the US.\n",
      "compound: -0.296, neg: 0.216, neu: 0.784, pos: 0.0, \n",
      "electorate, the Opec ministers and their new important roles, The Israeli and Palestinian leaders, and somewhat importantly, Mother Nature.\n",
      "compound: 0.4228, neg: 0.0, neu: 0.817, pos: 0.183, \n",
      "Given that, and that we cannot afford to lose any more money, and that Var seems to be a problem, let's be as flat as possible.\n",
      "compound: -0.1134, neg: 0.097, neu: 0.823, pos: 0.081, \n",
      "I'm ok with spread risk  (not front to backs, but commodity spreads).\n",
      "compound: -0.0129, neg: 0.2, neu: 0.679, pos: 0.121, \n",
      "The morning meetings are not inspiring, and I don't have a real feel for  everyone's passion with respect to the markets.\n",
      "compound: 0.5815, neg: 0.095, neu: 0.655, pos: 0.25, \n",
      "As such, I'd like to ask  John N. to run the morning meetings on Mon.\n",
      "compound: 0.3612, neg: 0.0, neu: 0.848, pos: 0.152, \n",
      "and Wed.\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n",
      "Thanks.\n",
      "compound: 0.4404, neg: 0.0, neu: 0.0, pos: 1.0, \n",
      "Jeff\n",
      "compound: 0.0, neg: 0.0, neu: 1.0, pos: 0.0, \n"
     ]
    }
   ],
   "source": [
    "# below is the sentiment analysis code rewritten for sentence-level analysis\n",
    "# note the new module -- word_tokenize!\n",
    "import nltk.data\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk import sentiment\n",
    "from nltk import word_tokenize\n",
    "\n",
    "# Next, we initialize VADER so we can use it within our Python script\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "# We will also initialize our 'english.pickle' function and give it a short name\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "message_text = '''It seems to me we are in the middle of no man's land with respect to the  following:  Opec production speculation, Mid east crisis and renewed  tensions, US elections and what looks like a slowing economy (?), and no real weather anywhere in the world. I think it would be most prudent to play  the markets from a very flat price position and try to day trade more aggressively. I have no intentions of outguessing Mr. Greenspan, the US. electorate, the Opec ministers and their new important roles, The Israeli and Palestinian leaders, and somewhat importantly, Mother Nature.  Given that, and that we cannot afford to lose any more money, and that Var seems to be a problem, let's be as flat as possible. I'm ok with spread risk  (not front to backs, but commodity spreads). The morning meetings are not inspiring, and I don't have a real feel for  everyone's passion with respect to the markets.  As such, I'd like to ask  John N. to run the morning meetings on Mon. and Wed.  Thanks. Jeff'''\n",
    "\n",
    "# The tokenize method breaks up the paragraph into a list of strings. In this example, note that the tokenizer is confused by the absence of spaces after periods and actually fails to break up sentences in two instances. How might you fix that?\n",
    "\n",
    "sentences = tokenizer.tokenize(message_text)\n",
    "\n",
    "# We add the additional step of iterating through the list of sentences and calculating and printing polarity scores for each one.\n",
    "\n",
    "for sentence in sentences:\n",
    "        print(sentence)\n",
    "        scores = sid.polarity_scores(sentence)\n",
    "        for key in sorted(scores):\n",
    "                print('{0}: {1}, '.format(key, scores[key]), end='')\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "af29365a973779c9560d56e09334d0c9d23342aad144db3e18bca9328584f409"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
