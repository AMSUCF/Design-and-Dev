{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Eleven: PCA\n",
    "\n",
    "Drawing on our example from class and the discussion of PCA in Data-Sitters Club, \n",
    "\n",
    "- Import at least ten documents from files, using the OS module and any others relevant to process the text\n",
    "- Isolate a component (the example was nouns - try verbs or adjectives) using nltk and prepare appropriate sub-files for comparison on that axis\n",
    "- Load the documents and titles and run the contents through vectorize, using the provided boilerplate\n",
    "- Run a simple (2 word) vizualization comparing all texts\n",
    "- Run a full (PCA) vizualization comparing all texts using the provided PCA boilerplate. Note any interesting characteristics or outliers in a brief analysis\n",
    "\n",
    "Bonus Challenge: Depending on your interests, you might either try using an API to collect the texts rather than saving them to a directory, or you might use Bokeh to attempt an exportable visualization of some aspect of what you've collected."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
